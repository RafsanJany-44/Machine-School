{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqpdklIrEJ2u",
        "outputId": "08d8a616-4ac0-4d32-efc1-fd03b6cb9504"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEsFaHeE2Pss"
      },
      "source": [
        "###Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "9kW4Aq41M67a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01e19911-12c6-45c7-e70f-f0c93e7abd3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.8/dist-packages (0.8.1)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.8/dist-packages (from imbalanced-learn) (1.7.3)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.8/dist-packages (from imbalanced-learn) (1.21.6)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from imbalanced-learn) (1.2.0)\n",
            "Requirement already satisfied: scikit-learn>=0.24 in /usr/local/lib/python3.8/dist-packages (from imbalanced-learn) (1.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.24->imbalanced-learn) (3.1.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.8/dist-packages (7.7.1)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.8/dist-packages (from ipywidgets) (5.7.1)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.8/dist-packages (from ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.8/dist-packages (from ipywidgets) (7.9.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.8/dist-packages (from ipywidgets) (3.6.1)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from ipywidgets) (3.0.5)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.8/dist-packages (from ipywidgets) (5.3.4)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.8/dist-packages (from ipykernel>=4.5.1->ipywidgets) (6.0.4)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.8/dist-packages (from ipykernel>=4.5.1->ipywidgets) (6.1.12)\n",
            "Collecting jedi>=0.10\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pickleshare in /usr/local/lib/python3.8/dist-packages (from ipython>=4.0.0->ipywidgets) (0.7.5)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.8/dist-packages (from ipython>=4.0.0->ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.8/dist-packages (from ipython>=4.0.0->ipywidgets) (4.8.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.8/dist-packages (from ipython>=4.0.0->ipywidgets) (2.6.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from ipython>=4.0.0->ipywidgets) (2.0.10)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from ipython>=4.0.0->ipywidgets) (4.4.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.8/dist-packages (from ipython>=4.0.0->ipywidgets) (57.4.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.8/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets) (5.7.16)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from jedi>=0.10->ipython>=4.0.0->ipywidgets) (0.8.3)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.8/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (5.7.1)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.8/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.13.3)\n",
            "Requirement already satisfied: jinja2<=3.0.0 in /usr/local/lib/python3.8/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.11.3)\n",
            "Requirement already satisfied: nbconvert<6.0 in /usr/local/lib/python3.8/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (5.6.1)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.8/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.8.0)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.8/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.15.0)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.8/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (23.2.1)\n",
            "Requirement already satisfied: jupyter-core>=4.4.0 in /usr/local/lib/python3.8/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (5.1.3)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets) (2.8.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets) (0.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets) (1.15.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.8/dist-packages (from pexpect->ipython>=4.0.0->ipywidgets) (0.7.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2<=3.0.0->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.0.1)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.8/dist-packages (from jupyter-core>=4.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.6.2)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.8/dist-packages (from nbconvert<6.0->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.4)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.8/dist-packages (from nbconvert<6.0->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.8.4)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.8/dist-packages (from nbconvert<6.0->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.7.1)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.8/dist-packages (from nbconvert<6.0->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (5.0.1)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.8/dist-packages (from nbconvert<6.0->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.6.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.8/dist-packages (from nbconvert<6.0->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.5.0)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.8/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.3.3)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.8/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.16.2)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (5.10.2)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (22.2.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.19.3)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.8/dist-packages (from bleach->nbconvert<6.0->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.5.1)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from importlib-resources>=1.4.0->jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.11.0)\n",
            "Installing collected packages: jedi\n",
            "Successfully installed jedi-0.18.2\n"
          ]
        }
      ],
      "source": [
        "!pip install imbalanced-learn\n",
        "!pip install ipywidgets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "S6X6XwSVM67b"
      },
      "outputs": [],
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "import ipywidgets as widgets\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ESoueLt11P_w"
      },
      "outputs": [],
      "source": [
        "def dataset_balance(X_temp, y_temp):\n",
        "  smote = SMOTE()\n",
        "  X_temp, y_temp= smote.fit_resample(X_temp, y_temp)\n",
        "  return pd.concat([pd.DataFrame(X_temp), pd.DataFrame(y_temp)], axis=1)\n",
        "\n",
        "def Xy_balance(X_temp, y_temp):\n",
        "  smote = SMOTE()\n",
        "  return smote.fit_resample(X_temp, y_temp)\n",
        "\n",
        "def Search_Null(dataset):\n",
        "  dic={}\n",
        "  for col in list(dataset.columns):\n",
        "    rows = []\n",
        "    flage = 0\n",
        "    for row in range(dataset.shape[0]):\n",
        "      if str(dataset[col][row]) == \"nan\":\n",
        "        rows.append(row)\n",
        "        flage = 1\n",
        "    if flage ==1:\n",
        "      dic[col] = rows\n",
        "  \n",
        "  return dic\n",
        "\n",
        "\n",
        "def models_check_box(models):\n",
        "  from IPython.display import display\n",
        "  new_keys=[]\n",
        "  for i in models:\n",
        "    i=widgets.Checkbox(\n",
        "      value=False,\n",
        "      description=str(i),\n",
        "      disabled=False,\n",
        "      indent=False\n",
        "      )\n",
        "    display(i)\n",
        "    new_keys.append(i)\n",
        "  return new_keys\n",
        "\n",
        "\n",
        "def StandardScaleData(data):\n",
        "  scaler = StandardScaler()\n",
        "  scaler.fit(data)\n",
        "  return  scaler.transform(data)\n",
        "\n",
        "\n",
        "def MinMaxScaleData(data):\n",
        "  scaler = MinMaxScaler()\n",
        "  scaler.fit(data)\n",
        "  return scaler.transform(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1B_8Nsw9-1Q"
      },
      "source": [
        "#Starting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Om8npCtFM67e",
        "outputId": "1551f557-5866-4cf9-b6b3-69e8fd714608"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(108920, 52)\n",
            "(108450, 52)\n"
          ]
        }
      ],
      "source": [
        "dataset = pd.read_csv(\"/content/drive/MyDrive/Sleep Stage 5 class/EEG_HMC_FeatureExtraction_2023.01.19.csv\")\n",
        "print(dataset.shape)\n",
        "dataset.dropna(axis = 0,how='any', inplace = True)\n",
        "dataset = dataset.reset_index(drop = True)\n",
        "\"\"\"df.to_csv(\"New_EEG_NullValueRemoved_HMC.csv\",index = False)\n",
        "dataset = pd.read_csv(\"New_EEG_NullValueRemoved_HMC.csv\")\"\"\"\n",
        "target = \"Sleep Stage\"\n",
        "result = {}\n",
        "print(dataset.shape)\n",
        "\n",
        "#Encoding\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "encoder=LabelEncoder()\n",
        "dataset[target]=encoder.fit_transform(dataset[target])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXMKr8bi2JnW"
      },
      "source": [
        "###Spliting into X and y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "tIf-rcIB11o1"
      },
      "outputs": [],
      "source": [
        "X =  dataset.loc[:,dataset.columns != target]  # removing Sleep Stage\n",
        "X =  X.loc[:,X.columns != \"Subject\"]            # removing Status\n",
        "X =  X.loc[:,X.columns != \"Epoch\"]             # removing Epoch\n",
        "y = dataset[target]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZLedhGD91Cv"
      },
      "source": [
        "#Feature Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "V1m6UgTv92XU"
      },
      "outputs": [],
      "source": [
        "number_of_feat = 30"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XkC7pB1v-Gsp"
      },
      "source": [
        "###ANOVA with f classifciation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Rafbj3rl-GWZ"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import make_classification\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import f_classif\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "\n",
        "fs = SelectKBest(score_func=f_classif, k=5)\n",
        "fit = fs.fit(X,y)\n",
        "dfscores = pd.DataFrame(fit.scores_)\n",
        "dfcolumns = pd.DataFrame(X.columns)\n",
        "\n",
        "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
        "\n",
        "featureScores.columns = ['Best_columns','Score_ANOVA'] \n",
        "\n",
        "lyst = featureScores.nlargest(number_of_feat,'Score_ANOVA')\n",
        "\n",
        "#lyst.to_csv('Filter_Method_ANOVA_with_f_classif.csv')\n",
        "\n",
        "list_of_feat = list(lyst[\"Best_columns\"])\n",
        "selection_method = \"ANOVA\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCkHXMQQ-PoJ"
      },
      "source": [
        "###Embedded Method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PZJcRlL7-So6"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LassoCV\n",
        "reg = LassoCV()\n",
        "reg.fit(X, y)\n",
        "print(\"Best alpha using built-in LassoCV: %f\" % reg.alpha_)\n",
        "print(\"Best score using built-in LassoCV: %f\" %reg.score(X,y))\n",
        "coef = pd.Series(reg.coef_, index = X.columns)\n",
        "\n",
        "print(\"Lasso picked \" + str(sum(coef != 0)) + \" variables and eliminated the other \" +  str(sum(coef == 0)) + \" variables\")\n",
        "\n",
        "imp_coef = coef.sort_values()\n",
        "\n",
        "list_of_feat=[]\n",
        "\n",
        "\n",
        "for i in range(coef.shape[0]):\n",
        "  if coef[i]!=0:\n",
        "    list_of_feat.append(dataset.iloc[:0,i+3].name)\n",
        "    \n",
        "df = pd.DataFrame(list_of_feat, columns=['Best_Features'])\n",
        "\n",
        "#df.to_csv(\"Embedded_Method.csv\")\n",
        "\n",
        "list_of_feat = list(df[\"Best_Features\"])\n",
        "if number_of_feat < len(list_of_feat):\n",
        "  list_of_feat = list_of_feat[:number_of_feat]\n",
        "selection_method = \"Embedded\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrR11h2K-aJn"
      },
      "source": [
        "###Pearson's with f regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qH6yDZiP-a9K"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import make_regression\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import f_regression\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "fs = SelectKBest(score_func=f_regression, k=5)\n",
        "fit = fs.fit(X,y)\n",
        "\n",
        "dfscores = pd.DataFrame(fit.scores_)\n",
        "dfcolumns = pd.DataFrame(dataset.columns)\n",
        "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
        "\n",
        "featureScores.columns = ['Best_columns','Score_pearsons'] \n",
        "\n",
        "\n",
        "lyst = featureScores.nlargest(number_of_feat,'Score_pearsons')\n",
        "\n",
        "#lyst.to_csv('Filter_Method_Pearson’s_with_f_regression.csv')\n",
        "\n",
        "list_of_feat = list(lyst[\"Best_columns\"])\n",
        "selection_method = \"Pearson\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85wbxGFW-kGZ"
      },
      "source": [
        "###Sequential Feature Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MtP9AHew-k1i"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_selection import SequentialFeatureSelector\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knn = KNeighborsClassifier(n_neighbors=3)\n",
        "sfs = SequentialFeatureSelector(knn, n_features_to_select=number_of_feat)\n",
        "sfs.fit(X, y)\n",
        "list_of_feat=[]\n",
        "list_of_feat=list(sfs.get_feature_names_out(X.columns))\n",
        "\n",
        "df = pd.DataFrame(list_of_feat, columns=['Best_Features'])\n",
        "\n",
        "#df.to_csv(\"Filter_Method_Sequential_feat_Selection_KNN.csv\")\n",
        "\n",
        "list_of_feat = list(df[\"Best_Features\"])\n",
        "if number_of_feat < len(list_of_feat):\n",
        "  list_of_feat = list_of_feat[:number_of_feat]\n",
        "\n",
        "selection_method = \"Sequential\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YAQ71nBV-p7E"
      },
      "source": [
        "###Feature list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JKwGHUuo-qnn"
      },
      "outputs": [],
      "source": [
        "dfcolumns = pd.DataFrame(list_of_feat)\n",
        "print(dfcolumns)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X=dataset[list_of_feat]\n",
        "y=dataset[target]\n",
        "print(X.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PllEtT-oHVK5",
        "outputId": "0af5b4b1-453b-4892-f778-bade3c34e3a1"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(108450, 30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Tunning for Scalling and Data Balancing"
      ],
      "metadata": {
        "id": "D_JvHx9vH9uj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Smote : NO\n",
        "##Scaling : NO"
      ],
      "metadata": {
        "id": "ZON5Lja3IgmX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tune_1():\n",
        "  X_new = X\n",
        "  y_new = y\n",
        "  return train_test_split(X_new, y_new, test_size = 0.2, random_state = 0)"
      ],
      "metadata": {
        "id": "eKyCe2mWINsz"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Smote : NO\n",
        "##Scaling : All Data (Standard)"
      ],
      "metadata": {
        "id": "SIo5zjE7IygQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tune_2():\n",
        "  X_new = StandardScaleData(X)\n",
        "  y_new = y\n",
        "  return train_test_split(X_new, y_new, test_size = 0.2, random_state = 0)"
      ],
      "metadata": {
        "id": "4mo8T61ZJKCm"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Smote : NO\n",
        "##Scaling : All Data (MinMax)"
      ],
      "metadata": {
        "id": "w8nhK0R1I754"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tune_3():\n",
        "  X_new = MinMaxScaleData(X)\n",
        "  y_new = y\n",
        "  return train_test_split(X_new, y_new, test_size = 0.2, random_state = 0)"
      ],
      "metadata": {
        "id": "nXhPKzRfJKwL"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Smote : NO\n",
        "##Scaling : Train (Stadard)"
      ],
      "metadata": {
        "id": "jENNmiyhJHz5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tune_4():\n",
        "  X_new = X\n",
        "  y_new = y\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X_new, y_new, test_size = 0.2, random_state = 0)\n",
        "  X_train = StandardScaleData(X_train)\n",
        "  return X_train, X_test, y_train, y_test"
      ],
      "metadata": {
        "id": "W-SONiQJJisq"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Smote : NO\n",
        "##Scaling : Train (MinMax)"
      ],
      "metadata": {
        "id": "80s0imm4Jlow"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def tune_5():\n",
        "  X_new = X\n",
        "  y_new = y\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X_new, y_new, test_size = 0.2, random_state = 0)\n",
        "  X_train = MinMaxScaleData(X_train)\n",
        "  return X_train, X_test, y_train, y_test"
      ],
      "metadata": {
        "id": "m994BnU1Jpdz"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Smote : ALL\n",
        "##Scaling : NO"
      ],
      "metadata": {
        "id": "AK88Z5f_Jo66"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def tune_6():\n",
        "  X_new,y_new = Xy_balance(X,y)\n",
        "  return train_test_split(X_new, y_new, test_size = 0.2, random_state = 0)\n"
      ],
      "metadata": {
        "id": "tp9qRMpgKcIc"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Smote : Train\n",
        "##Scaling : NO"
      ],
      "metadata": {
        "id": "00MAoDtaKcxo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def tune_7():\n",
        "  X_new = X\n",
        "  y_new = y\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X_new, y_new, test_size = 0.2, random_state = 0)\n",
        "  X_train,y_train = Xy_balance(X_train,y_train)\n",
        "  return X_train, X_test, y_train, y_test\n"
      ],
      "metadata": {
        "id": "nIzsgHkSKgrU"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Smote : Train\n",
        "##Scaling : Train (Standard)"
      ],
      "metadata": {
        "id": "kojmHdSZKhBy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tune_8():\n",
        "  X_new = X\n",
        "  y_new = y\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X_new, y_new, test_size = 0.2, random_state = 0)\n",
        "  X_train,y_train = Xy_balance(X_train,y_train)\n",
        "  X_train = StandardScaleData(X_train)\n",
        "  return X_train, X_test, y_train, y_test"
      ],
      "metadata": {
        "id": "VrY3vpP-Kvs-"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Smote : Train\n",
        "##Scaling : Train (MixMax)"
      ],
      "metadata": {
        "id": "7rX7q69eKwGB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tune_9():\n",
        "  X_new = X\n",
        "  y_new = y\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X_new, y_new, test_size = 0.2, random_state = 0)\n",
        "  X_train,y_train = Xy_balance(X_train,y_train)\n",
        "  X_train = MinMaxScaleData(X_train)\n",
        "  return X_train, X_test, y_train, y_test"
      ],
      "metadata": {
        "id": "p7aoyjE6Qll9"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Smote : All\n",
        "##Scaling : Train (Standard)"
      ],
      "metadata": {
        "id": "lSWIB7piKzlI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tune_10():\n",
        "  X_new,y_new = Xy_balance(X,y)\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X_new, y_new, test_size = 0.2, random_state = 0)\n",
        "  X_train = StandardScaleData(X_train)\n",
        "  return X_train, X_test, y_train, y_test "
      ],
      "metadata": {
        "id": "sa8IIKzeLKUj"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Smote : All\n",
        "##Scaling : Train (MixMax)"
      ],
      "metadata": {
        "id": "Z_0kWnD7LKzB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tune_11():\n",
        "  X_new,y_new = Xy_balance(X,y)\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X_new, y_new, test_size = 0.2, random_state = 0)\n",
        "  X_train = MinMaxScaleData(X_train)\n",
        "  return X_train, X_test, y_train, y_test "
      ],
      "metadata": {
        "id": "RkauvB9HLN2H"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Smote : All\n",
        "##Scaling : All (Standard)"
      ],
      "metadata": {
        "id": "_hIY_DerLOWn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tune_12():\n",
        "  X_new,y_new = Xy_balance(X,y)\n",
        "  X_new = StandardScaleData(X_new)\n",
        "  return train_test_split(X_new, y_new, test_size = 0.2, random_state = 0)"
      ],
      "metadata": {
        "id": "lFrLXHWNLRp1"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Smote : All\n",
        "##Scaling : ALL (MinMax)"
      ],
      "metadata": {
        "id": "7HwOO1ijLYvE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tune_13():\n",
        "  X_new,y_new = Xy_balance(X,y)\n",
        "  X_new = MinMaxScaleData(X_new)\n",
        "  return train_test_split(X_new, y_new, test_size = 0.2, random_state = 0)"
      ],
      "metadata": {
        "id": "zpz5l64YLZ00"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Tunn Dictionary"
      ],
      "metadata": {
        "id": "tIBhslqzApW8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tune_dic={\n",
        "  \"Smote : NO    ; Scaling : NO\"                  : tune_1(),\n",
        "  \"Smote : NO    ; Scaling : All Data(Standard)\"  : tune_2(),\n",
        "  \"Smote : NO    ; Scaling : All Data(MinMax)\"    : tune_3(),\n",
        "  \"Smote : NO    ; Scaling : Train(Standard)\"     : tune_4(),\n",
        "  \"Smote : NO    ; Scaling : Train(MinMax)\"       : tune_5(),\n",
        "  \"Smote : ALL   ; Scaling : NO\"                  : tune_6(),\n",
        "  \"Smote : Train ; Scaling : NO\"                  : tune_7(),\n",
        "  \"Smote : Train ; Scaling : Train(Standard)\"     : tune_8(),\n",
        "  \"Smote : Train ; Scaling : Train(MinMax)\"       : tune_9(),\n",
        "  \"Smote : All   ; Scaling : Train(Standard)\"     : tune_10(),\n",
        "  \"Smote : All   ; Scaling : Train(MinMax)\"       : tune_11(),\n",
        "  \"Smote : All   ; Scaling : All(Standard)\"       : tune_12(),\n",
        "  \"Smote : All   ; Scaling : All(Standard)\"       : tune_13()\n",
        "}"
      ],
      "metadata": {
        "id": "7fPzUhPb7nb9"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqYsoblRogp2"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IqElxazTzXxp"
      },
      "source": [
        "# **Training**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEe2R0yAoifa"
      },
      "source": [
        "##ADABOOST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bz_yVJaXod8O",
        "outputId": "ac954d91-8082-46aa-fa3c-f80a3e08478d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Smote : NO    ; Scaling : NO\n",
            "Accurecy:  0.5649608114338405\n",
            "------------------------------------------------------------------------------\n",
            "------------------------------------------------------------------------------\n",
            "Smote : NO    ; Scaling : All Data(Standard)\n",
            "Accurecy:  0.5649147072383587\n",
            "------------------------------------------------------------------------------\n",
            "------------------------------------------------------------------------------\n",
            "Smote : NO    ; Scaling : All Data(MinMax)\n",
            "Accurecy:  0.5649147072383587\n",
            "------------------------------------------------------------------------------\n",
            "------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/base.py:443: UserWarning: X has feature names, but AdaBoostClassifier was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Smote : NO    ; Scaling : Train(Standard)\n",
            "Accurecy:  0.17450437989857076\n",
            "------------------------------------------------------------------------------\n",
            "------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/base.py:443: UserWarning: X has feature names, but AdaBoostClassifier was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Smote : NO    ; Scaling : Train(MinMax)\n",
            "Accurecy:  0.37869986168741354\n",
            "------------------------------------------------------------------------------\n",
            "------------------------------------------------------------------------------\n",
            "Smote : ALL   ; Scaling : NO\n",
            "Accurecy:  0.5464390788272294\n",
            "------------------------------------------------------------------------------\n",
            "------------------------------------------------------------------------------\n",
            "Smote : Train ; Scaling : NO\n",
            "Accurecy:  0.5256339326878746\n",
            "------------------------------------------------------------------------------\n",
            "------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/base.py:443: UserWarning: X has feature names, but AdaBoostClassifier was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Smote : Train ; Scaling : Train(Standard)\n",
            "Accurecy:  0.12618718303365606\n",
            "------------------------------------------------------------------------------\n",
            "------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/base.py:443: UserWarning: X has feature names, but AdaBoostClassifier was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Smote : Train ; Scaling : Train(MinMax)\n",
            "Accurecy:  0.2516828031350853\n",
            "------------------------------------------------------------------------------\n",
            "------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/base.py:443: UserWarning: X has feature names, but AdaBoostClassifier was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Smote : All   ; Scaling : Train(Standard)\n",
            "Accurecy:  0.2855584863548747\n",
            "------------------------------------------------------------------------------\n",
            "------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/base.py:443: UserWarning: X has feature names, but AdaBoostClassifier was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Smote : All   ; Scaling : Train(MinMax)\n",
            "Accurecy:  0.3004971086537486\n",
            "------------------------------------------------------------------------------\n",
            "------------------------------------------------------------------------------\n",
            "Smote : All   ; Scaling : All(Standard)\n",
            "Accurecy:  0.5465658922593081\n",
            "------------------------------------------------------------------------------\n",
            "------------------------------------------------------------------------------\n",
            "CPU times: user 5min 15s, sys: 350 ms, total: 5min 15s\n",
            "Wall time: 5min 15s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "ada_defult = AdaBoostClassifier(random_state=0)\n",
        "\n",
        "ada={}\n",
        "for i in list(tune_dic.keys()):\n",
        "\n",
        "  X_train, X_test, y_train, y_test = tune_dic[i]\n",
        "  ada_defult.fit(X_train, y_train)\n",
        "  y_pred = ada_defult.predict(X_test)\n",
        "\n",
        "  from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "  accu = accuracy_score(y_test, y_pred)\n",
        "  print(i)\n",
        "  print(\"Accurecy: \",accu)\n",
        "  ada[i] = accu\n",
        "  print(\"------------------------------------------------------------------------------\")\n",
        "  print(\"------------------------------------------------------------------------------\")\n",
        "\n",
        "df = pd.DataFrame.from_dict(ada, orient=\"index\")\n",
        "df.to_csv(selection_method+\"_\"+str(number_of_feat)+\"_features_ada.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQhATacCo1AD"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJybpt_UvCU0"
      },
      "source": [
        "##Graddient Boosting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgmvc8A_o18j",
        "outputId": "3e0613a0-98db-4c24-e2ca-3d599aa53e0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Smote : NO    ; Scaling : NO\n",
            "Accurecy:  0.6614107883817427\n",
            "------------------------------------------------------------------------------\n",
            "------------------------------------------------------------------------------\n",
            "Smote : NO    ; Scaling : All Data(Standard)\n",
            "Accurecy:  0.6643153526970954\n",
            "------------------------------------------------------------------------------\n",
            "------------------------------------------------------------------------------\n",
            "Smote : NO    ; Scaling : All Data(MinMax)\n",
            "Accurecy:  0.6601659751037344\n",
            "------------------------------------------------------------------------------\n",
            "------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/base.py:443: UserWarning: X has feature names, but GradientBoostingClassifier was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Smote : NO    ; Scaling : Train(Standard)\n",
            "Accurecy:  0.177731673582296\n",
            "------------------------------------------------------------------------------\n",
            "------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/base.py:443: UserWarning: X has feature names, but GradientBoostingClassifier was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Smote : NO    ; Scaling : Train(MinMax)\n",
            "Accurecy:  0.4024896265560166\n",
            "------------------------------------------------------------------------------\n",
            "------------------------------------------------------------------------------\n",
            "Smote : ALL   ; Scaling : NO\n",
            "Accurecy:  0.6454550065942984\n",
            "------------------------------------------------------------------------------\n",
            "------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "gradBoost_default = GradientBoostingClassifier(random_state=0)\n",
        "\n",
        "grad={}\n",
        "\n",
        "for i in list(tune_dic.keys()):\n",
        "\n",
        "  X_train, X_test, y_train, y_test = tune_dic[i]\n",
        "  gradBoost_default.fit(X_train, y_train)\n",
        "  y_pred = gradBoost_default.predict(X_test)\n",
        "\n",
        "  from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "  accu = accuracy_score(y_test, y_pred)\n",
        "  print(i)\n",
        "  print(\"Accurecy: \",accu)\n",
        "  grad[i] = accu\n",
        "  print(\"------------------------------------------------------------------------------\")\n",
        "  print(\"------------------------------------------------------------------------------\")\n",
        "\n",
        "df = pd.DataFrame.from_dict(grad, orient=\"index\")\n",
        "df.to_csv(selection_method+\"_\"+str(number_of_feat)+\"_features_grad.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Histogram-Based Gradient Boosting"
      ],
      "metadata": {
        "id": "e1Tco70euelI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "\n",
        "hisgradBoost_default = HistGradientBoostingClassifier(random_state=0)\n",
        "\n",
        "hisgrad={}\n",
        "\n",
        "for i in list(tune_dic.keys()):\n",
        "  X_train, X_test, y_train, y_test = tune_dic[i]\n",
        "  \n",
        "  hisgradBoost_default.fit(X_train, y_train)\n",
        "  y_pred = hisgradBoost_default.predict(X_test)\n",
        "\n",
        "  from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "  accu = accuracy_score(y_test, y_pred)\n",
        "  print(i)\n",
        "  print(\"Accurecy: \",accu)\n",
        "  hisgrad[i] = accu\n",
        "  print(\"------------------------------------------------------------------------------\")\n",
        "  print(\"------------------------------------------------------------------------------\")\n",
        "\n",
        "df = pd.DataFrame.from_dict(hisgrad, orient=\"index\")\n",
        "df.to_csv(selection_method+\"_\"+str(number_of_feat)+\"_features_hisgrad.csv\")"
      ],
      "metadata": {
        "id": "BEpdNycHuifn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ThoTlhc4pRJT"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgMT_U8gvM7F"
      },
      "source": [
        "##Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-4GMunEvtWk2"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "RanFor={}\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf_default = RandomForestClassifier(random_state=0,n_jobs=-1)\n",
        "\n",
        "\n",
        "for i in list(tune_dic.keys()):\n",
        "\n",
        "  X_train, X_test, y_train, y_test = tune_dic[i]\n",
        "  rf_default.fit(X_train, y_train)\n",
        "  y_pred=rf_default.predict(X_test)\n",
        "\n",
        "\n",
        "  from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "  accu = accuracy_score(y_test, y_pred)\n",
        "  print(i)\n",
        "  print(\"Accurecy: \",accu)\n",
        "  RanFor[i] = accu\n",
        "  print(\"------------------------------------------------------------------------------\")\n",
        "  print(\"------------------------------------------------------------------------------\")\n",
        "\n",
        "df = pd.DataFrame.from_dict(RanFor, orient=\"index\")\n",
        "df.to_csv(selection_method+\"_\"+str(number_of_feat)+\"_features_RanFora.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_DChNuquB92"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRG4cBnKvZU2"
      },
      "source": [
        "##XGB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sC1lAZeeuCw8"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "import xgboost as xgb\n",
        "li = [\"Smote : NO    ; Scaling : Train(Standard)\",\n",
        "      \"Smote : NO    ; Scaling : Train(MinMax)\",\n",
        "      \"Smote : Train ; Scaling : Train(Standard)\",\n",
        "      \"Smote : Train ; Scaling : Train(MinMax)\",\n",
        "      \"Smote : All   ; Scaling : Train(Standard)\",\n",
        "      \"Smote : All   ; Scaling : Train(MinMax)\"]\n",
        "xgb_deafult = xgb.XGBClassifier(random_state=0,n_jobs=-1)\n",
        "\n",
        "xgb={}\n",
        "\n",
        "for i in list(tune_dic.keys()):\n",
        "\n",
        "  X_train, X_test, y_train, y_test = tune_dic[i]\n",
        "\n",
        "  if i in li:\n",
        "    xgb_deafult.fit(X_train,y_train.values)\n",
        "    y_pred = xgb_deafult.predict(X_test.values)\n",
        "  else:\n",
        "    xgb_deafult.fit(X_train,y_train)\n",
        "    y_pred = xgb_deafult.predict(X_test)\n",
        "\n",
        "\n",
        "  from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "  accu = accuracy_score(y_test, y_pred)\n",
        "  print(i)\n",
        "  print(\"Accurecy: \",accu)\n",
        "  xgb[i] = accu\n",
        "  print(\"------------------------------------------------------------------------------\")\n",
        "  print(\"------------------------------------------------------------------------------\")\n",
        "\n",
        "df = pd.DataFrame.from_dict(xgb, orient=\"index\")\n",
        "df.to_csv(selection_method+\"_\"+str(number_of_feat)+\"_features_xgb.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K6_icFWdauSI"
      },
      "source": [
        "##KNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6GALUBYbaz1z"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knn_default = KNeighborsClassifier(n_jobs = -1)\n",
        "\n",
        "knn={}\n",
        "for i in list(tune_dic.keys()):\n",
        "\n",
        "  X_train, X_test, y_train, y_test = tune_dic[i]\n",
        "  knn_default.fit(X_train, y_train)\n",
        "  y_pred=knn_default.predict(X_test)\n",
        "\n",
        "\n",
        "  from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "  accu = accuracy_score(y_test, y_pred)\n",
        "  print(i)\n",
        "  print(\"Accurecy: \",accu)\n",
        "  knn[i] = accu\n",
        "  print(\"------------------------------------------------------------------------------\")\n",
        "  print(\"------------------------------------------------------------------------------\")\n",
        "\n",
        "df = pd.DataFrame.from_dict(knn, orient=\"index\")\n",
        "df.to_csv(selection_method+\"_\"+str(number_of_feat)+\"_features_knn.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Btki9jRvc1Y"
      },
      "source": [
        "##NB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iRmd7ve-ubcd"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "nb_deafult = GaussianNB()\n",
        "\n",
        "nb={}\n",
        "for i in list(tune_dic.keys()):\n",
        "\n",
        "  X_train, X_test, y_train, y_test = tune_dic[i]\n",
        "  nb_deafult.fit(X_train, y_train)\n",
        "  y_pred = nb_deafult.predict(X_test)\n",
        "\n",
        "\n",
        "  from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "  accu = accuracy_score(y_test, y_pred)\n",
        "  print(i)\n",
        "  print(\"Accurecy: \",accu)\n",
        "  nb[i] = accu\n",
        "  print(\"------------------------------------------------------------------------------\")\n",
        "  print(\"------------------------------------------------------------------------------\")\n",
        "\n",
        "df = pd.DataFrame.from_dict(nb, orient=\"index\")\n",
        "df.to_csv(selection_method+\"_\"+str(number_of_feat)+\"_features_nb.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Support Vector Machines"
      ],
      "metadata": {
        "id": "Pt_vcBAayRPD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####SVM"
      ],
      "metadata": {
        "id": "g21ALhCNyzOi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"%%time\n",
        "from sklearn import svm\n",
        "\n",
        "svm = svm.SVC(decision_function_shape='ovo')\n",
        "\n",
        "svm_svc={}\n",
        "for i in list(tune_dic.keys()):\n",
        "\n",
        "  X_train, X_test, y_train, y_test = tune_dic[i]\n",
        "  svm.fit(X_train, y_train)\n",
        "  y_pred = svm.predict(X_test)\n",
        "\n",
        "\n",
        "  from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "  accu = accuracy_score(y_test, y_pred)\n",
        "  print(i)\n",
        "  print(\"Accurecy: \",accu)\n",
        "  svm_svc[i] = accu\n",
        "  print(\"------------------------------------------------------------------------------\")\n",
        "  print(\"------------------------------------------------------------------------------\")\n",
        "\n",
        "df = pd.DataFrame.from_dict(svm_svc, orient=\"index\")\n",
        "df.to_csv(\"svm_svc.csv\")\"\"\""
      ],
      "metadata": {
        "id": "DLS5oXLVyVxx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Linear"
      ],
      "metadata": {
        "id": "G0C3fZ9Fy5Hi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"%%time\n",
        "from sklearn import svm\n",
        "\n",
        "LinearSVC = svm.LinearSVC()\n",
        "\n",
        "lin_svc = {}\n",
        "for i in list(tune_dic.keys()):\n",
        "\n",
        "  X_train, X_test, y_train, y_test = tune_dic[i]\n",
        "  LinearSVC.fit(X_train, y_train)\n",
        "  y_pred = LinearSVC.predict(X_test)\n",
        "\n",
        "\n",
        "\n",
        "  from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "  accu = accuracy_score(y_test, y_pred)\n",
        "  print(i)\n",
        "  print(\"Accurecy: \",accu)\n",
        "  lin_svc[i] = accu\n",
        "  print(\"------------------------------------------------------------------------------\")\n",
        "  print(\"------------------------------------------------------------------------------\")\n",
        "\n",
        "df = pd.DataFrame.from_dict(lin_svc, orient=\"index\")\n",
        "df.to_csv(\"lin_svc.csv\")\"\"\""
      ],
      "metadata": {
        "id": "7MSg2w8Syysp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Stochastic Gradient Descent"
      ],
      "metadata": {
        "id": "2px1l5lEzh0M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"%%time\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "SGDClassifier = SGDClassifier()\n",
        "\n",
        "sgdc={}\n",
        "for i in list(tune_dic.keys()):\n",
        "\n",
        "  X_train, X_test, y_train, y_test = tune_dic[i]\n",
        "  SGDClassifier.fit(X_train, y_train)\n",
        "  y_pred = SGDClassifier.predict(X_test)\n",
        "\n",
        "\n",
        "  from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "  accu = accuracy_score(y_test, y_pred)\n",
        "  print(i)\n",
        "  print(\"Accurecy: \",accu)\n",
        "  sgdc[i] = accu\n",
        "  print(\"------------------------------------------------------------------------------\")\n",
        "  print(\"------------------------------------------------------------------------------\")\n",
        "\n",
        "df = pd.DataFrame.from_dict(sgdc, orient=\"index\")\n",
        "df.to_csv(\"sgdc.csv\")\"\"\""
      ],
      "metadata": {
        "id": "vJag2atpzho8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Tree algorithms"
      ],
      "metadata": {
        "id": "F5nb6RJK0RYl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###DecisionTreeRegressor"
      ],
      "metadata": {
        "id": "pInu7aUH0U5l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "dtc = DecisionTreeClassifier()\n",
        "\n",
        "dt={}\n",
        "for i in list(tune_dic.keys()):\n",
        "\n",
        "  X_train, X_test, y_train, y_test = tune_dic[i]\n",
        "  dtc.fit(X_train, y_train)\n",
        "  y_pred = dtc.predict(X_test)\n",
        "\n",
        "\n",
        "  from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "  accu = accuracy_score(y_test, y_pred)\n",
        "  print(i)\n",
        "  print(\"Accurecy: \",accu)\n",
        "  dt[i] = accu\n",
        "  print(\"------------------------------------------------------------------------------\")\n",
        "  print(\"------------------------------------------------------------------------------\")\n",
        "\n",
        "df = pd.DataFrame.from_dict(dt, orient=\"index\")\n",
        "df.to_csv(selection_method+\"_\"+str(number_of_feat)+\"_features_dt.csv\")"
      ],
      "metadata": {
        "id": "ab5w_XIS0Ub8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost\n",
        "\n",
        "from catboost import CatBoostClassifier\n",
        "\n",
        "#cat = CatBoostClassifier(task_type=\"GPU\")\n",
        "\n",
        "cat=CatBoostClassifier()\n",
        "\n",
        "catb={}\n",
        "for i in list(tune_dic.keys()):\n",
        "\n",
        "  X_train, X_test, y_train, y_test = tune_dic[i]\n",
        "  cat.fit(X_train,y_train)\n",
        "  y_pred = cat.predict(X_test)\n",
        "\n",
        "  from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "  accu = accuracy_score(y_test, y_pred)\n",
        "  print(i)\n",
        "  print(\"Accurecy: \",accu)\n",
        "  catb[i] = accu\n",
        "  print(\"------------------------------------------------------------------------------\")\n",
        "  print(\"------------------------------------------------------------------------------\")\n",
        "\n",
        "df = pd.DataFrame.from_dict(catb, orient=\"index\")\n",
        "df.to_csv(selection_method+\"_\"+str(number_of_feat)+\"_features_catb.csv\")"
      ],
      "metadata": {
        "id": "Ft-htE7P-iA3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqsWPAB3uv72"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "rrR11h2K-aJn",
        "85wbxGFW-kGZ",
        "YAQ71nBV-p7E",
        "jEe2R0yAoifa",
        "FJybpt_UvCU0",
        "AgMT_U8gvM7F",
        "jRG4cBnKvZU2",
        "K6_icFWdauSI",
        "_Btki9jRvc1Y",
        "znXNx2bgUvtd",
        "zxxWSX26jsGT",
        "XtgWbvJsEwMt"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}